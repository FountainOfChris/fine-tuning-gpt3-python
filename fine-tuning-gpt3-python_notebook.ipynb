{"cells":[{"source":"[DataCamp Tutorial Link](https://app.datacamp.com/learn/tutorials/fine-tuning-gpt-3-using-the-open-ai-api-and-python)","metadata":{},"cell_type":"markdown","id":"05ee8296-c84e-497d-8311-e5d562df9249"},{"source":"## Dataset\nIn this use case, we will fine-tune the GPT-3 model for a question-answering scenario, consisting of a structured question-answer pattern designed to help the model understand the task the model needs to perform. A consistent format is maintained for each pair of questions and answers across the entire training and testing data.\n\nAn instance in the question-answering dataset has the following format:","metadata":{},"cell_type":"markdown","id":"bcb3e5f3-4e07-4b1c-8fa1-49fead506ec1"},{"source":"{\n\"prompt\": \"my prompt ->\",\n\"completion\": \"the answer of the prompt. \\n\"\n}","metadata":{"executionCancelledAt":null,"executionTime":146,"lastExecutedAt":1715016996163,"lastExecutedByKernel":"dee06774-d266-418c-a7a6-494e6fb6fb91","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"{\n\"prompt\": \"my prompt ->\",\n\"completion\": \"the answer of the prompt. \\n\"\n}"},"cell_type":"code","id":"af35b022-f6a1-4a36-aad8-c770054fe7f7","outputs":[{"output_type":"execute_result","data":{"text/plain":"{'prompt': 'my prompt ->', 'completion': 'the answer of the prompt. \\n'}"},"metadata":{},"execution_count":1}],"execution_count":1},{"source":"- “prompt” is the input text read and processed by the model. The main separator is the arrow sign (->) to delineate the prompt from the expected response.\n- “completion” is the expected response to the prompt. A backslash “\\n” sign is used as a stop sequence to indicate the end of the answer.\n\nWith this understanding of the format of the dataset, we can generate both the training and the validation dataset, as shown below. These prompts and completions have been generated using ChatGPT.","metadata":{},"cell_type":"markdown","id":"5636e2ff-a755-4515-889d-370b7dc5263f"},{"source":"training_data = [\n\t{\n    \t\"prompt\": \"What is the capital of France?->\",\n    \t\"completion\": \"\"\" The capital of France is Paris.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"What is the primary function of the heart?->\",\n    \t\"completion\": \"\"\" The primary function of the heart is to pump blood throughout the body.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"What is photosynthesis?->\",\n    \t\"completion\": \"\"\" Photosynthesis is the process by which green plants and some other organisms convert sunlight into chemical energy stored in the form of glucose.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"Who wrote the play 'Romeo and Juliet'?->\",\n    \t\"completion\": \"\"\" William Shakespeare wrote the play 'Romeo and Juliet'.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"Which element has the atomic number 1?->\",\n    \t\"completion\": \"\"\" Hydrogen has the atomic number 1.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"What is the largest planet in our solar system?->\",\n    \t\"completion\": \"\"\" Jupiter is the largest planet in our solar system.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"What is the freezing point of water in Celsius?->\",\n    \t\"completion\": \"\"\" The freezing point of water in Celsius is 0 degrees.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"What is the square root of 144?->\",\n    \t\"completion\": \"\"\" The square root of 144 is 12.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"Who is the author of 'To Kill a Mockingbird'?->\",\n    \t\"completion\": \"\"\" The author of 'To Kill a Mockingbird' is Harper Lee.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"What is the smallest unit of life?->\",\n    \t\"completion\": \"\"\" The smallest unit of life is the cell.\\n\"\"\"\n\t}\n]\n\nvalidation_data = [\n\t{\n    \t\"prompt\": \"Which gas do plants use for photosynthesis?->\",\n    \t\"completion\": \"\"\" Plants use carbon dioxide for photosynthesis.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"What are the three primary colors of light?->\",\n    \t\"completion\": \"\"\" The three primary colors of light are red, green, and blue.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"Who discovered penicillin?->\",\n    \t\"completion\": \"\"\" Sir Alexander Fleming discovered penicillin.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"What is the chemical formula for water?->\",\n    \t\"completion\": \"\"\" The chemical formula for water is H2O.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"What is the largest country by land area?->\",\n    \t\"completion\": \"\"\" Russia is the largest country by land area.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"What is the speed of light in a vacuum?->\",\n    \t\"completion\": \"\"\" The speed of light in a vacuum is approximately 299,792 kilometers per second.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"What is the currency of Japan?->\",\n    \t\"completion\": \"\"\" The currency of Japan is the Japanese Yen.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"What is the smallest bone in the human body?->\",\n    \t\"completion\": \"\"\" The stapes, located in the middle ear, is the smallest bone in the human body.\\n\"\"\"\n\t}\n]","metadata":{"executionCancelledAt":null,"executionTime":14,"lastExecutedAt":1715017000334,"lastExecutedByKernel":"dee06774-d266-418c-a7a6-494e6fb6fb91","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"training_data = [\n\t{\n    \t\"prompt\": \"What is the capital of France?->\",\n    \t\"completion\": \"\"\" The capital of France is Paris.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"What is the primary function of the heart?->\",\n    \t\"completion\": \"\"\" The primary function of the heart is to pump blood throughout the body.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"What is photosynthesis?->\",\n    \t\"completion\": \"\"\" Photosynthesis is the process by which green plants and some other organisms convert sunlight into chemical energy stored in the form of glucose.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"Who wrote the play 'Romeo and Juliet'?->\",\n    \t\"completion\": \"\"\" William Shakespeare wrote the play 'Romeo and Juliet'.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"Which element has the atomic number 1?->\",\n    \t\"completion\": \"\"\" Hydrogen has the atomic number 1.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"What is the largest planet in our solar system?->\",\n    \t\"completion\": \"\"\" Jupiter is the largest planet in our solar system.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"What is the freezing point of water in Celsius?->\",\n    \t\"completion\": \"\"\" The freezing point of water in Celsius is 0 degrees.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"What is the square root of 144?->\",\n    \t\"completion\": \"\"\" The square root of 144 is 12.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"Who is the author of 'To Kill a Mockingbird'?->\",\n    \t\"completion\": \"\"\" The author of 'To Kill a Mockingbird' is Harper Lee.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"What is the smallest unit of life?->\",\n    \t\"completion\": \"\"\" The smallest unit of life is the cell.\\n\"\"\"\n\t}\n]\n\nvalidation_data = [\n\t{\n    \t\"prompt\": \"Which gas do plants use for photosynthesis?->\",\n    \t\"completion\": \"\"\" Plants use carbon dioxide for photosynthesis.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"What are the three primary colors of light?->\",\n    \t\"completion\": \"\"\" The three primary colors of light are red, green, and blue.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"Who discovered penicillin?->\",\n    \t\"completion\": \"\"\" Sir Alexander Fleming discovered penicillin.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"What is the chemical formula for water?->\",\n    \t\"completion\": \"\"\" The chemical formula for water is H2O.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"What is the largest country by land area?->\",\n    \t\"completion\": \"\"\" Russia is the largest country by land area.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"What is the speed of light in a vacuum?->\",\n    \t\"completion\": \"\"\" The speed of light in a vacuum is approximately 299,792 kilometers per second.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"What is the currency of Japan?->\",\n    \t\"completion\": \"\"\" The currency of Japan is the Japanese Yen.\\n\"\"\"\n\t},\n\t{\n    \t\"prompt\": \"What is the smallest bone in the human body?->\",\n    \t\"completion\": \"\"\" The stapes, located in the middle ear, is the smallest bone in the human body.\\n\"\"\"\n\t}\n]"},"cell_type":"code","id":"67fd0712-0e22-49e6-ad00-1581839534a2","outputs":[],"execution_count":2},{"source":"## Setup\nBefore diving into the implementation process, we need to prepare the working environment by installing the necessary libraries, especially the OpenAI Python library, as shown below:","metadata":{},"cell_type":"markdown","id":"1e448131-cd99-4924-87b0-63ccd6249c42"},{"source":"pip install --upgrade openai","metadata":{"executionCancelledAt":null,"executionTime":5894,"lastExecutedAt":1715017011513,"lastExecutedByKernel":"dee06774-d266-418c-a7a6-494e6fb6fb91","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"pip install --upgrade openai","outputsMetadata":{"0":{"height":616,"type":"stream"}}},"cell_type":"code","id":"55d5d996-316e-408c-9f2f-22f9559ca025","outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.14.2)\nCollecting openai\n  Downloading openai-1.25.2-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (4.3.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\nRequirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\nRequirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\nDownloading openai-1.25.2-py3-none-any.whl (312 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.9/312.9 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: openai\n\u001b[33m  WARNING: The script openai is installed in '/home/repl/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n\u001b[0mSuccessfully installed openai-1.25.2\nNote: you may need to restart the kernel to use updated packages.\n"}],"execution_count":3},{"source":"# Now we can import the library.\nimport os\nfrom openai import OpenAI\n\nclient = OpenAI(\n  api_key='OPENAI_API_KEY',\n)","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1715017098052,"lastExecutedByKernel":"dee06774-d266-418c-a7a6-494e6fb6fb91","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Now we can import the library.\nimport os\nfrom openai import OpenAI\n\nclient = OpenAI(\n  api_key='sk-proj-rdO2wpuGz7eQmv6bUaNmT3BlbkFJo6nk7fzxIzLKZ0m4ysOe',\n)"},"cell_type":"code","id":"13231478-b0d0-44fe-9168-bab7a9fcf02a","outputs":[],"execution_count":7},{"source":"## Prepare the dataset\nDealing with list format, as shown above, might be convenient for small datasets. However, there are several benefits to saving the data in JSONL (JSON Lines) format. The benefits include scalability, interoperability, simplicity, and also compatibility with OpenAI API, which requires data in JSONL format when creating fine-tuning jobs.\n\nThe following code leverages the helper function prepare_data to create both the training and validation data in JSONL formats:","metadata":{},"cell_type":"markdown","id":"f9e6313e-f753-4fbf-8e5e-e69078c80bb9"},{"source":"import json\n\ntraining_file_name = \"training_data.jsonl\"\nvalidation_file_name = \"validation_data.jsonl\"\n\ndef prepare_data(dictionary_data, final_file_name):\n    with open(final_file_name, 'w') as outfile:\n        for entry in dictionary_data:\n        \tjson.dump(entry, outfile)\n        \toutfile.write('\\n')\n\nprepare_data(training_data, \"training_data.jsonl\")\nprepare_data(validation_data, \"validation_data.jsonl\")","metadata":{"executionCancelledAt":null,"executionTime":40,"lastExecutedAt":1715017102263,"lastExecutedByKernel":"dee06774-d266-418c-a7a6-494e6fb6fb91","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import json\n\ntraining_file_name = \"training_data.jsonl\"\nvalidation_file_name = \"validation_data.jsonl\"\n\ndef prepare_data(dictionary_data, final_file_name):\n    with open(final_file_name, 'w') as outfile:\n        for entry in dictionary_data:\n        \tjson.dump(entry, outfile)\n        \toutfile.write('\\n')\n\nprepare_data(training_data, \"training_data.jsonl\")\nprepare_data(validation_data, \"validation_data.jsonl\")"},"cell_type":"code","id":"90f8eff2-24ac-4473-b150-003242c413c4","outputs":[],"execution_count":8},{"source":"# Finally, we upload the two datasets to the OpenAI developer account as follows:\ntraining_file_id = client.files.create(\n  file=open(training_file_name, \"rb\"),\n  purpose=\"fine-tune\"\n)\n\nvalidation_file_id = client.files.create(\n  file=open(validation_file_name, \"rb\"),\n  purpose=\"fine-tune\"\n)\n\nprint(f\"Training File ID: {training_file_id}\")\nprint(f\"Validation File ID: {validation_file_id}\")","metadata":{"executionCancelledAt":null,"executionTime":1226,"lastExecutedAt":1715017107083,"lastExecutedByKernel":"dee06774-d266-418c-a7a6-494e6fb6fb91","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Finally, we upload the two datasets to the OpenAI developer account as follows:\ntraining_file_id = client.files.create(\n  file=open(training_file_name, \"rb\"),\n  purpose=\"fine-tune\"\n)\n\nvalidation_file_id = client.files.create(\n  file=open(validation_file_name, \"rb\"),\n  purpose=\"fine-tune\"\n)\n\nprint(f\"Training File ID: {training_file_id}\")\nprint(f\"Validation File ID: {validation_file_id}\")","outputsMetadata":{"0":{"height":101,"type":"stream"}}},"cell_type":"code","id":"b2724935-a3a0-468b-8f25-f70c0954c219","outputs":[{"output_type":"stream","name":"stdout","text":"Training File ID: FileObject(id='file-JYlfaCtbyvtCSh3QK19p6B3I', bytes=1310, created_at=1715017106, filename='training_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\nValidation File ID: FileObject(id='file-YdYNmDYKa0wHwlx52XVHlHud', bytes=1036, created_at=1715017106, filename='validation_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n"}],"execution_count":9},{"source":"At this level we have all the information to proceed with the fine-tuning.","metadata":{},"cell_type":"markdown","id":"a3d3cedb-3d88-41f1-8e1b-bb0ea7fd156e"},{"source":"## Create a fine-tuning job\nThis fine-tuning process is highly inspired by the openai-cookbook performing fine-tuning on Microsoft Azure.\n\nTo perform the fine-tuning we will use the following two steps: (1) define hyperparameters, and (2) trigger the fine-tuning.\n\nWe will fine-tune the davinci model and run it for 15 epochs using a batch size of 3 and a learning rate multiplier of 0.3 using the training and validation datasets.","metadata":{},"cell_type":"markdown","id":"dcbd98c7-1cc7-4ee7-8e67-f1c8778b8958"},{"source":"response = client.fine_tuning.jobs.create(\n  training_file=training_file_id.id, \n  validation_file=validation_file_id.id,\n  model=\"davinci-002\", \n  hyperparameters={\n    \"n_epochs\": 15,\n\t\"batch_size\": 3,\n\t\"learning_rate_multiplier\": 0.3\n  }\n)\njob_id = response.id\nstatus = response.status\n\nprint(f'Fine-tunning model with jobID: {job_id}.')\nprint(f\"Training Response: {response}\")\nprint(f\"Training Status: {status}\")","metadata":{"executionCancelledAt":null,"executionTime":2331,"lastExecutedAt":1715017185294,"lastExecutedByKernel":"dee06774-d266-418c-a7a6-494e6fb6fb91","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"response = client.fine_tuning.jobs.create(\n  training_file=training_file_id.id, \n  validation_file=validation_file_id.id,\n  model=\"davinci-002\", \n  hyperparameters={\n    \"n_epochs\": 15,\n\t\"batch_size\": 3,\n\t\"learning_rate_multiplier\": 0.3\n  }\n)\njob_id = response.id\nstatus = response.status\n\nprint(f'Fine-tunning model with jobID: {job_id}.')\nprint(f\"Training Response: {response}\")\nprint(f\"Training Status: {status}\")","outputsMetadata":{"0":{"height":185,"type":"stream"}}},"cell_type":"code","id":"61cf936a-68e2-430d-b47d-d1bf8a14ac7d","outputs":[{"output_type":"stream","name":"stdout","text":"Fine-tunning model with jobID: ftjob-lQ4C2kINNxwOjFECUHDXI9cl.\nTraining Response: FineTuningJob(id='ftjob-lQ4C2kINNxwOjFECUHDXI9cl', created_at=1715017185, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=15, batch_size=3, learning_rate_multiplier=0.3), model='davinci-002', object='fine_tuning.job', organization_id='org-QyCbEbjEnJX56aeephKkhuEJ', result_files=[], seed=1688150027, status='validating_files', trained_tokens=None, training_file='file-JYlfaCtbyvtCSh3QK19p6B3I', validation_file='file-YdYNmDYKa0wHwlx52XVHlHud', estimated_finish=None, integrations=[], user_provided_suffix=None)\nTraining Status: validating_files\n"}],"execution_count":10},{"source":"This pending status does not provide any relevant information. However, we can have more insight into the training process by running the following code:","metadata":{},"cell_type":"markdown","id":"d89b479c-94c7-4045-a1db-b51b65a28f11"},{"source":"import signal\nimport datetime\n\n\ndef signal_handler(sig, frame):\n    status = client.fine_tuning.jobs.retrieve(job_id).status\n    print(f\"Stream interrupted. Job is still {status}.\")\n    return\n\n\nprint(f\"Streaming events for the fine-tuning job: {job_id}\")\n\nsignal.signal(signal.SIGINT, signal_handler)\n\nevents = client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id)\ntry:\n    for event in events:\n        print(\n            f'{datetime.datetime.fromtimestamp(event.created_at)} {event.message}'\n        )\nexcept Exception:\n    print(\"Stream interrupted (client disconnected).\")","metadata":{"executionCancelledAt":null,"executionTime":312,"lastExecutedAt":1715017214164,"lastExecutedByKernel":"dee06774-d266-418c-a7a6-494e6fb6fb91","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import signal\nimport datetime\n\n\ndef signal_handler(sig, frame):\n    status = client.fine_tuning.jobs.retrieve(job_id).status\n    print(f\"Stream interrupted. Job is still {status}.\")\n    return\n\n\nprint(f\"Streaming events for the fine-tuning job: {job_id}\")\n\nsignal.signal(signal.SIGINT, signal_handler)\n\nevents = client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id)\ntry:\n    for event in events:\n        print(\n            f'{datetime.datetime.fromtimestamp(event.created_at)} {event.message}'\n        )\nexcept Exception:\n    print(\"Stream interrupted (client disconnected).\")","outputsMetadata":{"0":{"height":143,"type":"stream"}}},"cell_type":"code","id":"1a52a733-98f9-460b-93fe-ac834df0e265","outputs":[{"output_type":"stream","name":"stdout","text":"Streaming events for the fine-tuning job: ftjob-lQ4C2kINNxwOjFECUHDXI9cl\n2024-05-06 17:40:11 Fine-tuning job started\n2024-05-06 17:40:08 Files validated, moving job to queued state\n2024-05-06 17:39:45 Validating training file: file-JYlfaCtbyvtCSh3QK19p6B3I and validation file: file-YdYNmDYKa0wHwlx52XVHlHud\n2024-05-06 17:39:45 Created fine-tuning job: ftjob-lQ4C2kINNxwOjFECUHDXI9cl\n"}],"execution_count":11},{"source":"## Check the fine-tuning job status\nLet's verify that our operation was successful, and additionally, we can examine all the fine-tuning operations by using a list operation.","metadata":{},"cell_type":"markdown","id":"b6af922b-3398-4e2d-9d92-59e12bb7c174"},{"source":"import time\n\nstatus = client.fine_tuning.jobs.retrieve(job_id).status\nif status not in [\"succeeded\", \"failed\"]:\n    print(f\"Job not in terminal status: {status}. Waiting.\")\n    while status not in [\"succeeded\", \"failed\"]:\n        time.sleep(2)\n        status = client.fine_tuning.jobs.retrieve(job_id).status\n        print(f\"Status: {status}\")\nelse:\n    print(f\"Finetune job {job_id} finished with status: {status}\")\nprint(\"Checking other finetune jobs in the subscription.\")\nresult = client.fine_tuning.jobs.list()\nprint(f\"Found {len(result.data)} finetune jobs.\")","metadata":{"executionCancelledAt":null,"executionTime":329304,"lastExecutedAt":1715017564394,"lastExecutedByKernel":"dee06774-d266-418c-a7a6-494e6fb6fb91","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import time\n\nstatus = client.fine_tuning.jobs.retrieve(job_id).status\nif status not in [\"succeeded\", \"failed\"]:\n    print(f\"Job not in terminal status: {status}. Waiting.\")\n    while status not in [\"succeeded\", \"failed\"]:\n        time.sleep(2)\n        status = client.fine_tuning.jobs.retrieve(job_id).status\n        print(f\"Status: {status}\")\nelse:\n    print(f\"Finetune job {job_id} finished with status: {status}\")\nprint(\"Checking other finetune jobs in the subscription.\")\nresult = client.fine_tuning.jobs.list()\nprint(f\"Found {len(result.data)} finetune jobs.\")","outputsMetadata":{"0":{"height":616,"type":"stream"}}},"cell_type":"code","id":"a564f153-75e8-4265-88a8-a2e922d05f20","outputs":[{"output_type":"stream","name":"stdout","text":"Job not in terminal status: running. Waiting.\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: running\nStatus: succeeded\nChecking other finetune jobs in the subscription.\nFound 1 finetune jobs.\n"}],"execution_count":12},{"source":"## Validation of the model\nFinally, the fine-tuned model can be retrieved from the “fine_tuned_model” attribute. ","metadata":{},"cell_type":"markdown","id":"87f0f2b4-aad8-4d3e-9e1a-47d6e005a109"},{"source":"# Retrieve the finetuned model\nfine_tuned_model = result.data[0].fine_tuned_model\nprint(fine_tuned_model)","metadata":{"executionCancelledAt":null,"executionTime":12,"lastExecutedAt":1715017573682,"lastExecutedByKernel":"dee06774-d266-418c-a7a6-494e6fb6fb91","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Retrieve the finetuned model\nfine_tuned_model = result.data[0].fine_tuned_model\nprint(fine_tuned_model)","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"d7644f9f-08e9-4d8c-9818-54c7aafee3a0","outputs":[{"output_type":"stream","name":"stdout","text":"ft:davinci-002:personal::9LwhF1E1\n"}],"execution_count":13},{"source":"With this model, we can run queries to validate its results by providing a prompt, the model name, and creating a query with the openai.Completion.create() function. The result is retrieved from the answer dictionary as follows:","metadata":{},"cell_type":"markdown","id":"5f7c4e1b-badb-4490-9f9c-a9c48544122d"},{"source":"new_prompt = \"Which part is the smallest bone in the entire human body?\"\nanswer = client.completions.create(\n  model=fine_tuned_model,\n  prompt=new_prompt\n)\n\nprint(answer.choices[0].text)\n\nnew_prompt = \"Which type of gas is utilized by plants during the process of photosynthesis?\"\nanswer = client.completions.create(\n  model=fine_tuned_model,\n  prompt=new_prompt\n)\n\nprint(answer.choices[0].text)","metadata":{"executionCancelledAt":null,"executionTime":5580,"lastExecutedAt":1715017604800,"lastExecutedByKernel":"dee06774-d266-418c-a7a6-494e6fb6fb91","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"new_prompt = \"Which part is the smallest bone in the entire human body?\"\nanswer = client.completions.create(\n  model=fine_tuned_model,\n  prompt=new_prompt\n)\n\nprint(answer.choices[0].text)\n\nnew_prompt = \"Which type of gas is utilized by plants during the process of photosynthesis?\"\nanswer = client.completions.create(\n  model=fine_tuned_model,\n  prompt=new_prompt\n)\n\nprint(answer.choices[0].text)","outputsMetadata":{"0":{"height":101,"type":"stream"}}},"cell_type":"code","id":"dbcb3c46-4f0b-47ef-9415-d092903cb2e4","outputs":[{"output_type":"stream","name":"stdout","text":" Is it, now, there's a good question of your own.\n\nYou got\n What will be the waste product when the gas is passed by a plumber through a\n"}],"execution_count":14}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}